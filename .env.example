# NadirClaw Configuration
# Copy to .env and fill in your values

# Auth token (optional — disabled by default for local use)
# Set this if you want to require a bearer token:
# NADIRCLAW_AUTH_TOKEN=your-secret-token

# ── Tier Model Config (recommended) ──────────────────────────
# Explicitly set which model handles each tier.
# LiteLLM auto-detects the provider from the model name.
NADIRCLAW_SIMPLE_MODEL=ollama/llama3.1:8b
NADIRCLAW_COMPLEX_MODEL=claude-sonnet-4-20250514

# ── Example configurations ────────────────────────────────────
# Claude + Ollama (default):
#   NADIRCLAW_SIMPLE_MODEL=ollama/llama3.1:8b
#   NADIRCLAW_COMPLEX_MODEL=claude-sonnet-4-20250514
#
# Claude + Claude (quality tiers):
#   NADIRCLAW_SIMPLE_MODEL=claude-haiku-4-20250514
#   NADIRCLAW_COMPLEX_MODEL=claude-sonnet-4-20250514
#
# OpenAI + Ollama:
#   NADIRCLAW_SIMPLE_MODEL=ollama/llama3.1:8b
#   NADIRCLAW_COMPLEX_MODEL=gpt-4o
#
# OpenAI + OpenAI:
#   NADIRCLAW_SIMPLE_MODEL=gpt-4o-mini
#   NADIRCLAW_COMPLEX_MODEL=gpt-4o

# ── Legacy model list (fallback if tier vars not set) ─────────
# NADIRCLAW_MODELS=claude-sonnet-4-20250514,ollama/llama3.1:8b

# ── Provider API keys ──────────────────────────────────────────
# These are optional if you use 'nadirclaw auth' to store credentials.
# Credentials are resolved in order: OpenClaw → nadirclaw auth → env var.
# ANTHROPIC_API_KEY=sk-ant-...
# OPENAI_API_KEY=sk-...

# Ollama base URL (default: http://localhost:11434)
OLLAMA_API_BASE=http://localhost:11434

# Classification confidence threshold (default: 0.06)
# Lower = more prompts classified as complex (safer but more expensive)
NADIRCLAW_CONFIDENCE_THRESHOLD=0.06

# Server port (default: 8000)
NADIRCLAW_PORT=8000

# Log directory (default: ~/.nadirclaw/logs)
NADIRCLAW_LOG_DIR=~/.nadirclaw/logs
